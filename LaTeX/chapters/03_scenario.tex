\chapter{Scenario and Problem Statement}

In this chapter, we introduce the considered scenario and give details on the
system, network and control models assumed in Sec.~\ref{sec:system},
Sec.~\ref{sec:network} and Sec.~\ref{sec:control} respectively.
Section~\ref{sec:problem} formulates the wireless resource scheduling problem as
an optimal control problem to be solved by the proposed scheduling scheme.

\section{System Model} \label{sec:system} 

\begin{figure}[htb]
  \centering
  \resizebox*{.8\textwidth}{!}{\input{figures/scenario}} 
  \caption[Scheme of $N$ sub-systems sharing a wireless communication
  medium]{Considered scenario with $N$ heterogeneous LTI networked control
  systems. Solid lines indicate ideal controller-to-plant and plant-to-sensor
  links. Sensor-to-controller links are closed over a shared wireless channel.
  Medium access is granted centrally by a scheduler. Note that $k_i$ refers to
  the sampling period a sub-system $i$ is in.}
  \label{fig:scenario}
\end{figure}

We consider $N$ independent, linear time-invariant (LTI) control systems sharing
a wireless communication network. Each individual sub-system $i$ consists of a
plant $\plant$, a sensor $\sensor$ and a controller $\controller$ with an
estimator $\estimator$. Every sensor $\sensor$ measures the output of the plant
periodically and sends the latest sample to $\controller$. On the controller
side, $\estimator$ estimates the current plant state based on the latest
received information. Estimated state is then used by $\controller$ to calculate
the next control input. Each controller-plant pair is assumed to be connected
through an ideal link, while the sensor is operating remotely over the shared
wireless channel as illustrated in Fig.~\ref{fig:scenario}.

\section{Network Model} \label{sec:network} 

In our scenario we consider time to progress in discrete time slots and use $t
\in \mathbb{N}$ to index them. Sensors $\sensor$ transmit state information over
a wireless medium in packets containing a single measurement. We assume
simplified packet transmission, where each packet sent in slot $t$ is received
within the same slot and packets are neither acknowledged nor retransmitted to
reduce protocol overhead. Medium access is granted by a centralized entity
called \textit{scheduler}, which at each time slot $t$ decides which sub-system
is allowed to transmit its latest plant measurement. Moreover, only a single
transmission resource is allocated within a single time slot. Let $\delta_i(t)
\in \left\{0,1\right\}$ denote the scheduler decision variable being
$\delta_i(t)=1$ if the sub-system $i$ is allowed to transmit in slot $t$ and
$\delta_i(t)=0$ otherwise. Then the following holds for all time slots:

\begin{equation}
  \sum_{i=1}^{N}{\delta_i(t) \leq 1 \quad, \forall t}
\end{equation}

We consider a bursty GE channel where the link quality between each
sensor-controller pair is time and channel state dependent. (See
Sec.~{\ref{sec:GE}}) Each link is prone to its own channel state $q_i(t)$ which
determines the probability $p_i(t) \in \left\{p_G,p_B\right\}$ a packet is lost
with. That is, if we define a success indicator variable $\gamma_i(t)\in\{0,1\}$
representing a failed $\gamma_i(t)=0$ or a successful $\gamma_i(t)=1$ packet
reception, then the probabilities for a success and failure are given by
$\Pr[\gamma_i(t)=1 \mid \delta_i(t)=1] = 1-p_i(t)$ and  $\Pr[\gamma_i(t)=0 \mid
\delta_i(t)=1] = p_i(t)$, respectively. \\ 
% For the sake of completeness, note that $\Pr[\gamma_i[t]=1 \mid \delta_i[t]=0]
% = 0$ and $\Pr[\gamma_i[t]=0 \mid \delta_i[t]=0] = 1$. 
The control-aware scheduler is assumed to be able to measure the instantaneous
link quality for each sensor-estimator pair, thus knows the current loss
probabilities $p_i(t)$. Further, the scheduler will make decisions by
considering control and network behaviors. The network state is comprised of
variables defined in the following.

\subsection{Network state}

Packets are generated periodically at $\sensor$ every $D_i \in \mathbb{Z}^+$
slots. We refer to the generation of a packet as a \textit{sampling event} and
the time between two consecutive sampling events as the \textit{sampling
period}. Let $t_{i,o} \sim \mathcal{U}[0, D_i)$ denote the initial sampling
event of sub-system $i$, then the set of slots in which a sampling event occurs
are:

\begin{equation}
  \mathcal{G}_i \triangleq \lbrace t_{i,o}, \; t_{i,o} + D_{i}, \; t_{i,o} + 2 D_{i}, \; \dots \rbrace 
\end{equation}

As $t_{i,o}$ is a uniformly distributed random variable and not necessarily
equal for each sub-system, we allow sampling to operate in a non-synchronized
fashion. 

\begin{figure}[htb]
  \centering
  \resizebox*{.6\textwidth}{!}{\input{figures/ageplot}} 

  \caption[Example evolution of generation time $t_{i,g}$, received time
  $t_{i,r}$ and update time $t_{i,u}$]{Evolution of generation time
  $t_{i,g}(t)$, received time $t_{i,r}(t)$ and the update time $t_{i,u}(t)$.
  $t_{i,g}(t)$ and $t_{i,u}(t)$ update their values periodically every $D_i$
  slots, while $t_{i,r}(t)$ can progress asynchronously. Two exemplary
  successful packet transmission $\delta_i(t_{1,2})=1$ are illustrated.}
  \label{fig:ageplot}
\end{figure}  

The controller does not benefit from receiving an older plant measurement, if it
has already received a more recent measurement \cite{costa2016age}. Therefore,
sensors replace their packet in the transmit buffer with a more recent
measurement whenever a newer update arrives. We define a variable $t_{i,g}(t)$
that denotes the time the packet waiting for transmission at $\sensor$ was
generated. Since packets are solely generated during a sampling event, $t \in
\mathcal{G}_i$ are the only possible values $t_{i,g}$ can have. Thus, $t_{i,g}$
evolves as follows:

\begin{equation}
  t_{i,g}(t+1) =
  \begin{cases}
  t+1 & \text{, if } t+1 \in \mathcal{G}_i \\
  t_{i,g}(t) & \text{, otherwise}	
  \end{cases}
\end{equation}

We further define $t_{i,r}(t)$ as the generation time of the newest packet
received by $\controller$ until time $t$:

\begin{equation}
  t_{i, r}(t+1) =
  \begin{cases}
  t_{i, g}(t) & \text{, if } \delta_i(t) \cdot \gamma_i(t) = 1 \\
  t_{i, r}(t) & \text{, otherwise}	
  \end{cases}
\end{equation}

Fig.~\ref{fig:ageplot} shows an exemplary evolution of $t_{i,g}$, along with how
${t_{i,r}(t+1)}$ and $t_{i,g}(t)$ are correlated to each other after two
successful updates. Generation time $t_{i,g}$ demonstrates a discrete staircase
behavior at $t \in \mathcal{G}_i$, while received time $t_{i,r}$ can take new
values at any slot $t \in \mathbb{N}$ subject to the indication variables
$\delta_i$ and $\gamma_i$.

\section{Control Model} \label{sec:control}

The system of the $i$-th plant $\plant$ is considered to evolve by the following
LTI model over discrete time:

\begin{equation}
  \label{eq:discretemodel}
  \boldsymbol{x}_i[k_i+1] = \boldsymbol{A}_i \boldsymbol{x}_i[k_i] + \boldsymbol{B}_i \boldsymbol{u}_i[k_i] + \boldsymbol{w}_i[k_i]
\end{equation}

with time-invariant system matrix $\boldsymbol{A}_i \in \mathbb{R}^{n_i\times
n_i}$ and input matrix $\boldsymbol{B}_i \in \mathbb{R}^{n_i\times m_i}$. System
noise is denoted by $\boldsymbol{w}_i \in \mathbb{R}^{n_i}$ which is
characterized by a multi-variate Gaussian distribution with zero mean and
diagonal covariance matrix $\mathbf{\Sigma}_i \in \mathbb{R}^{n_i}$, i.e.,
$\boldsymbol{w}_i \sim \mathcal{N}(\mathbf{0}, \mathbf{\Sigma}_i)$. We assume
the sub-systems to operate slower than the network. In other words, the plant
state changes only after each sampling event and remains constant until the next
one. Thus, the discrete dynamics of sub-systems as described in
Eq.~\eqref{eq:discretemodel} is indexed by a different time variable $k_i$. It
indicates in which sampling period a sub-system currently is and can be obtained
at any time slot $t$ with:

\begin{equation}
  \label{eq:k_map}
	k_i(t) = \floor{\frac{t - t_{i,o}}{D_i}}
\end{equation}

In addition, $\boldsymbol{x}_i[k_i] \in \mathbb{R}^{n_i}$ and
$\boldsymbol{u}_i[k_i] \in \mathbb{R}^{m_i}$ represent the system state and
control input in sampling period $k_i$, respectively. At the beginning of each
sampling period $k_i$, i.e., at $t=t_{i,o}+k_iD_i$, the controller $\controller$
calculates $\boldsymbol{u}_i[k]$ given the available observation history and
actuates $\plant$ with the obtained control input within the same sampling
period. As a result, any packet arriving in sampling period $k_i$ after
$\boldsymbol{u}_i[k_i]$ is calculated, will be queued until it is first utilized
in the next control input $\boldsymbol{u}_i[k_i+1]$. To capture the
aforementioned update delay of successfully received packets, we introduce
$t_{i,u}(t)$ as the generation time of the latest utilized packet by
$\controller$:

\begin{equation}
  \label{eq:t_u}
  t_{i, u}(t+1) =
  \begin{cases}
  t_{i, r}(t+1) & \text{, if } t+1 \in \mathcal{G}_i \\ 
  t_{i, u}(t) & \text{, otherwise}	
  \end{cases} 
\end{equation}

Time dynamics of $t_{i,u}$ is seen in Fig.~\ref{fig:ageplot} where it takes the
value of $t_{i,r}$ at the end of a control system period $t \in \mathcal{G}_i$.

\subsection{Age-of-Information Model}
The discrete-time model allows for communication and control to evolve in
different time steps. Particularly, changes in our control model occur at
sampling events. Thus, in a control application's point of view, plant
observations included in packets age only every $D_i$ slots. Information
staleness is then expressed in multiples of $D_i$. Therefore, we define AoI as
the number of sampling periods elapsed since the acquisition of the latest
received system state at $\controller$ and can be determined at any slot $t$ as:

\begin{equation}
  \label{eq:aoi}
  \Delta_i(t) = \ceil{\dfrac{t - t_{i,u}(t)}{D_{i}}} 
\end{equation}

It should be noted that since packets arrive at least one slot delayed, a packet
received in a sampling period can never be utilized immediately in the same
sampling period. Hence, the minimum AoI in our scenario is one, i.e.,
$\Delta_i(t) \ge 1,\forall i,t$.

\subsection{Remote Estimation and Control Law}
In order to compensate for packet drops or delays caused by the network, each
controller $\controller$ employs a Kalman-like state estimator $\estimator$
based on the following assumptions:

\begin{theorem}
  The controller $\controller$ and its estimator $\estimator$ are aware of the
  control system parameters $\boldsymbol{A}_i, \boldsymbol{B}_i$ and
  $\boldsymbol{w}_i$.
\end{theorem}

\begin{theorem}
  $t_{i,o}, D_i$ and $t$ are also known by the controller. 
\end{theorem}

Assumption 1 is motivated by the time-invariant nature of the sub-system's
dynamics. Assumption 2 allows the estimation-based controller to map any $t$ to
$k_i$ by using Eq.~\eqref{eq:k_map}. As a result, the controller can determine
the AoI of its most up-to-date plant state information $\boldsymbol{x_i}[k_i -
\Delta_i[k_i]]$ which is $\Delta_i[k_i]$ sampling periods old.

Combining our assumptions, each estimator $\estimator$ predicts the current
plant state by means of a conditional expectation, i.e.,
$\hat{\boldsymbol{x}}_i[k_i] = \E\left[\boldsymbol{x}_i[k_i] \mid \Delta_i[k_i],
\boldsymbol{x}_i[k_i-\Delta_i] \right]$. We leverage the results from
\cite{ayan2019age}, stating that the optimal estimation which minimizes the
mean-squared error is obtained by:

\begin{equation}
  \label{eq:estimatedstate}
    \boldsymbol{\hat{x}}_i[k_i] = \boldsymbol{A}_i^{\Delta_i[k_i]} \,  \boldsymbol{x}_i[k_i - \Delta_i[k_i]] + \sum_{q=1}^{\Delta_i[k_i]} \boldsymbol{A}_i^{q - 1} \, \boldsymbol{B}_i \, \boldsymbol{u}_i [k_i - q].
\end{equation}

To perform this estimation, $\estimator$ has to keep track of the last
$\Delta_i[k_i]$ control inputs. However, this information is generated locally
and thus already available to $\estimator$. Further, with
Eq.~\eqref{eq:discretemodel} and \eqref{eq:estimatedstate} the estimation error
$\boldsymbol{e}_i[k_i]$ is obtained as:

\begin{equation}
  \boldsymbol{e}_i[k_i] \triangleq \boldsymbol{x}_i[k_i] - \boldsymbol{\hat{x}}_i[k_i] = \sum_{q=1}^{\Delta_i[k_i]} \boldsymbol{A}_i^{q-1} \, \boldsymbol{w}_i[k_i - q].
\end{equation}

By taking the euclidean norm of $\boldsymbol{e}_i[k_i]$ the expected mean
squared error (MSE) at $\controller$ is given as:

\begin{align}
  \label{eq:estimationerror}
  \E \left[ \left(\boldsymbol{e}_i[k_i]\right)^T \, \boldsymbol{e}_i[k_i]\right] & = \sum_{r=1}^{\Delta_i[k_i] - 1} \tr \left( \left(\boldsymbol{A}_i^T\right)^r  \left(\boldsymbol{A}_i \right)^r \boldsymbol{\Sigma}_i \right) \\ \nonumber
  & \triangleq g(\Delta_i[k_i]).
\end{align}

It is important to note that Eq.~\eqref{eq:estimationerror} only depends on
$\Delta_i[k_i]$ and is independent from the actual system state
$\boldsymbol{x}_i[k_i]$. This would not be true in the case of time-variant
control systems. Here, we define $g(\Delta_i[k_i])$ as our AoI-based age-penalty
that penalizes high estimation errors and will be subject to minimization in the
scheduling problem.

After obtaining a state estimation, it is utilized in calculating the control
input according to the following control law:

\begin{equation}
  \label{eq:controllaw}
  \boldsymbol{u}_i[k_i] = - \boldsymbol{L}_i^* \,\boldsymbol{\hat{x}}_i[k_i],
\end{equation}

where $\boldsymbol{L}_i^* \in \mathbb{R}^{m_i \times n_i}$ is the feedback gain
matrix. 

% $\boldsymbol{L}^*_i$ is obtained from:
% \begin{equation}
%   \label{eq:optimalgain}
%   \boldsymbol{L}_i^* = \left(\boldsymbol{R}_i + \boldsymbol{B}_i^T \boldsymbol{P}_i \boldsymbol{B}_i \right)^{-1} \boldsymbol{B}_i^T \boldsymbol{P}_i \boldsymbol{A}_i,
% \end{equation}

% which solves the discrete time algebraic Riccati equation:
% \begin{equation}
%   \label{eq:riccati}
%   \boldsymbol{P}_i = \boldsymbol{Q}_{i} + \boldsymbol{A}_i^T \left(\boldsymbol{P}_i - \boldsymbol{P}_i \boldsymbol{B}_i ( \boldsymbol{R}_{i} + \boldsymbol{B}_i^T \boldsymbol{P}_i \boldsymbol{B}_i)^{- 1} \boldsymbol{B}_i^T \boldsymbol{P}_i \right) \boldsymbol{A}_i.
% \end{equation}

% $\boldsymbol{Q}_{i}$ and $\boldsymbol{R}_{i}$ are weighting matrices of
% appropriate size that penalize the state and control inputs in the infinite
% horizon, \textit{Linear-quadratic-Gaussian} (LQG) cost function $F_i$:

% \begin{equation}
%   F_i = \dfrac{1}{K} \limsup_{K \rightarrow \infty} \sum_{k_i=0}^{K-1} (\boldsymbol{x}_i[k_i])^T \boldsymbol{Q}_i \boldsymbol{x}_i[k_i] +  (\boldsymbol{u}_i[k_i])^T \boldsymbol{R}_i \boldsymbol{u}_i[k_i]. 
% \end{equation}

% One can interpret $F_i$ as an indicator of control performance. The lower $F_i$
% is, the higher is the \textit{quality of control}.

\section{Scheduling Problem Formulation} \label{sec:problem} 

From Eq.~\eqref{eq:estimationerror} it is evident, that expected estimation
performance is controlled by the AoI of sub-systems. By scheduling a certain
control application, information with low $\Delta_i[k_i]$ is provided to its
estimator, resulting in low age-penalties. In Ch~\ref{ch:scheduler} we will
derive a scheduler whose aim is to minimize the total expected cost and thereby
providing good overall estimation accuracy. Let $\mu(t')\in\left\{\varnothing,
1, \dots,N \right\}$ denote the scheduling decision at slot $t'$, which indexes
the sub-system that is granted medium access. Note that $\mu(t')=i$ implies
$\delta_i(t')=1$. We are interested in scheduling policies $\pi$ consisting of a
sequence of scheduling decisions $\mu(t')$ for the next $H \in \mathbb{Z}^+$
slots:

\begin{equation}
  \pi=\left\{ \mu(t), \mu(t+1), \dots, \mu(t+H-1) \right\}
\end{equation}

Such policies will be called \textit{admissible}. $H$ is the \textit{finite
horizon} parameter that defines how many future slots are being considered by
$\pi$. Thus, $H$ governs the ``farsightedness'' of the proposed scheduler.

We consider the wireless resource scheduling problem as a general problem of
decision under stochastic uncertainty \cite{bertsekas1995dynamic}. Such a
problem has two principal features. An underlying discrete-time dynamic system
and an \textit{additive} cost function $J$ that is dependent on the system's
state. In our case, the dynamic system is the wireless network whose system
state $\boldsymbol{s} \in \mathbb{Z}^{4\cdot N}$ we define as:

\begin{equation}
  \boldsymbol{s}(t) \triangleq \left[\boldsymbol{t}_g(t) \quad \boldsymbol{t}_r(t) \quad \boldsymbol{t}_u(t) \quad \boldsymbol{q}(t)\right]^T, 
\end{equation}   
with: 
\begin{align}
  \boldsymbol{t}_g(t) &\triangleq \left[ t_{1,g}(t) ~ \dots ~ t_{N,g}(t) \right]^T ,\\
  \boldsymbol{t}_r(t) &\triangleq \left[ t_{1,r}(t) ~ \dots ~ t_{N,r}(t) \right]^T ,\\
  \boldsymbol{t}_u(t) &\triangleq \left[ t_{1,u}(t) ~ \dots ~ t_{N,u}(t) \right]^T ,\\
  \boldsymbol{q}(t) &\triangleq \left[ q_1(t) ~ \dots ~ q_N(t) \right].
\end{align}  

The evolution of the network's state depends on the outcome of packet
transmissions over the wireless network. Otherwise speaking, network dynamics
are affected by random packet loss. As a consequence, given a ``control'' input
$\mu(t)$ not only one but multiple next network states are possible. Each of
these transitions follow a probability distribution $Pr\left[\cdot\mid\mu(t),
\boldsymbol{s}(t) \right]$. While possible next states are under the influence
of made scheduling decisions, their corresponding transition probability is a
function of $p_i(t)$ and $f,r$ defined by the GE model. Particularly, given a
state $\boldsymbol{s}(t)$ and a scheduling decision $\mu(t)=i$, the transition
probability to a possible next state $\boldsymbol{s'}$ is expressed by:

\begin{equation}
  \label{eq:transition}
  \Pr \left[ \boldsymbol{s}(t+1)=\boldsymbol{s}' \mid \mu(t)=i,\boldsymbol{s}(t)
  \right] \in \left\{ p \cdot q \mid p\in\mathcal{L},q\in\mathcal{T} \right\},
\end{equation}

where $\mathcal{L}=\left\{p_G,p_B\right\}^N$ are GE channel state dependent loss
probabilities and $\mathcal{T}=\left\{f,r\right\}$ the failure and recovery
rates defined in the Markov chain's stochastic transition matrix in
Eq.~\eqref{eq:GE_transition}.

Consider $C(\boldsymbol{s}(t))$ as state cost incurred by being in
$\boldsymbol{s}(t)$ at time $t$. To penalize high estimation errors, we define
$C(\boldsymbol{s}(t))$ as the total expected MSE over all sub-systems:

\begin{equation}
  \label{eq:gfunction}
  C(\boldsymbol{s}(t)) =  \sum_{i=1}^{N}  g(\Delta_i[k_i(t)]),
\end{equation}

where $g(\Delta_i[k_i(t)])$ is the expected estimation error of a single
sub-system as defined in Eq.~\eqref{eq:estimationerror}. 

The cost function $J$ is \textit{additive} over time in the sense that cost
acquired at time $t$, i.e., $C(\boldsymbol{s}(t))$, accumulates over time.
Meaning that the total expected finite horizon cost $J_{\pi}(\boldsymbol{s}(t))$
for any initial state $\boldsymbol{s}(t)$ and horizon $H$ is defined as:

\begin{equation}
  \label{eq:horizoncost}	
  J_\pi(\boldsymbol{s}(t)) \triangleq \E_\pi \left[ \sum_{t' = t }^{t + H} C(\boldsymbol{s}(t')) \right] 
\end{equation}

Note that since network transmissions occur stochastically,
$C(\boldsymbol{s}(t))$ is a random variable and therefore we consider the
expectation of the total cost. Further, as feasible next states depend on the
scheduling decisions $\mu(t')$, the subscript $\pi$ in $J_\pi$ and $\E_\pi$
indicate that Eq.~\eqref{eq:horizoncost} quantifies the expected cost when the
scheduling policy $\pi = \{ \mu(t), {\mu(t+1)}, \dots, \mu(t+H-1) \}$ is applied
over the horizon $H$. Our goal is to find the optimal policy $\pi^*$, such that
$J_{\pi^*}(\boldsymbol{s}(t))$ is minimal:

\begin{equation}
\label{eq:minimizationproblem}
	J_{\pi^*}(\boldsymbol{s}(t)) = \min_{\pi \in \Pi} J_\pi (\boldsymbol{s}(t)) = J^*(\boldsymbol{s}(t)),
\end{equation}

where $\Pi$ is the set of all admissible policies. In addition, to only allow
sub-systems with new information to transmit, we reduce the set of possible
actions given the network state $\boldsymbol{s}(t)$ at each time slot $t$ to:

\begin{gather}
  \label{eq:admissibleactions}
  \mathcal{M}(\boldsymbol{s}(t)) = \{\varnothing\} \cup \{i : t_{i,g}(t) > t_{i,r}(t) \}, \\
  \mu(t) \in \mathcal{M}(\boldsymbol{s}(t))
\end{gather}

This allows us to confine our search for an optimal scheduling policy within
this smaller set. Together with the search space, the scheduler's complexity is
also reduced without losing optimality. Throughout the remaining thesis, we
refer to the minimization problem in Eq.~\eqref{eq:minimizationproblem} as the
$H$-stage problem and drop the subscript $\pi$ for brevity.
